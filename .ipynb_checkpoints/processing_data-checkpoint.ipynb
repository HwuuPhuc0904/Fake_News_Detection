{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0a51f39-abf8-4381-9b95-1c88c00b5721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3008e32f-e2ed-4018-a9cb-3d934b8d465f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>post_message</th>\n",
       "      <th>timestamp_post</th>\n",
       "      <th>num_like_post</th>\n",
       "      <th>num_comment_post</th>\n",
       "      <th>num_share_post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>389c669730cb6c54314a46be785cea42</td>\n",
       "      <td>THƒÇNG C·∫§P B·∫¨C H√ÄM ƒê·ªêI V·ªöI 2 C√ÅN B·ªò, CHI·∫æN S·ª∏ H...</td>\n",
       "      <td>1585945439</td>\n",
       "      <td>19477</td>\n",
       "      <td>378</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>775baa6d037b6d359b229a656eaeaf08</td>\n",
       "      <td>&lt;URL&gt;</td>\n",
       "      <td>1588939166.0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>b9f3394d2aff86d85974f5040c401f08</td>\n",
       "      <td>T∆Ø V·∫§N M√ôA THI: C√°ch n·ªôp h·ªì s∆° ƒë·ªÉ tr√∫ng tuy·ªÉn ...</td>\n",
       "      <td>1591405213</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>808e278b22ec6b96f2faf7447d10cd8e</td>\n",
       "      <td>C∆° quan C·∫°nh tranh v√† Th·ªã tr∆∞·ªùng Anh quy·∫øt ƒë·ªãn...</td>\n",
       "      <td>1592023613</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>f81bdd6d8be4c5f64bb664214e47aced</td>\n",
       "      <td>Th√™m 7 ca t·∫°i Qu·∫£ng Nam li√™n quan ƒë·∫øn h√†nh kh√°...</td>\n",
       "      <td>1583737358</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id                         user_name  \\\n",
       "0           0   1  389c669730cb6c54314a46be785cea42   \n",
       "1           1   2  775baa6d037b6d359b229a656eaeaf08   \n",
       "2           2   3  b9f3394d2aff86d85974f5040c401f08   \n",
       "3           3   4  808e278b22ec6b96f2faf7447d10cd8e   \n",
       "4           4   5  f81bdd6d8be4c5f64bb664214e47aced   \n",
       "\n",
       "                                        post_message timestamp_post  \\\n",
       "0  THƒÇNG C·∫§P B·∫¨C H√ÄM ƒê·ªêI V·ªöI 2 C√ÅN B·ªò, CHI·∫æN S·ª∏ H...     1585945439   \n",
       "1                                              <URL>   1588939166.0   \n",
       "2  T∆Ø V·∫§N M√ôA THI: C√°ch n·ªôp h·ªì s∆° ƒë·ªÉ tr√∫ng tuy·ªÉn ...     1591405213   \n",
       "3  C∆° quan C·∫°nh tranh v√† Th·ªã tr∆∞·ªùng Anh quy·∫øt ƒë·ªãn...     1592023613   \n",
       "4  Th√™m 7 ca t·∫°i Qu·∫£ng Nam li√™n quan ƒë·∫øn h√†nh kh√°...     1583737358   \n",
       "\n",
       "  num_like_post num_comment_post num_share_post  label  \n",
       "0         19477              378          173.0      0  \n",
       "1            11                5              3      0  \n",
       "2            48                5           19.0      0  \n",
       "3             3                0            0.0      0  \n",
       "4           775                0           54.0      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/combined_datasets.csv', encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22382127-74fe-4538-ae4a-2ca9adac035a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_like_post has nan False\n",
      "num_comment_post has nan False\n",
      "num_share_post has nan False\n",
      "post_message has nan False\n"
     ]
    }
   ],
   "source": [
    "# fill 0 to num_like_post, num_commnet_post, num_share_post\n",
    "data.num_like_post.fillna(0, inplace=True)\n",
    "data.num_comment_post.fillna(0, inplace=True)\n",
    "data.num_share_post.fillna(0, inplace=True)\n",
    "data = data.dropna(subset=['post_message'], how='any').reset_index(drop=True)\n",
    "\n",
    "# check again\n",
    "check_like = data.num_like_post.isna().sum()\n",
    "check_commnet = data.num_comment_post.isna().sum()\n",
    "check_share = data.num_share_post.isna().sum()\n",
    "check_post_message = data.post_message.isna().sum()\n",
    "\n",
    "print(f'num_like_post has nan {check_like != 0}')\n",
    "print(f'num_comment_post has nan {check_commnet != 0}')\n",
    "print(f'num_share_post has nan {check_share != 0}')\n",
    "print(f'post_message has nan {check_post_message != 0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23dfd107-d114-4768-9dea-cead42dae3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>post_message</th>\n",
       "      <th>num_like_post</th>\n",
       "      <th>num_comment_post</th>\n",
       "      <th>num_share_post</th>\n",
       "      <th>label</th>\n",
       "      <th>user_name_labelEncoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>389c669730cb6c54314a46be785cea42</td>\n",
       "      <td>THƒÇNG C·∫§P B·∫¨C H√ÄM ƒê·ªêI V·ªöI 2 C√ÅN B·ªò, CHI·∫æN S·ª∏ H...</td>\n",
       "      <td>19477</td>\n",
       "      <td>378</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>b9f3394d2aff86d85974f5040c401f08</td>\n",
       "      <td>T∆Ø V·∫§N M√ôA THI: C√°ch n·ªôp h·ªì s∆° ƒë·ªÉ tr√∫ng tuy·ªÉn ...</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>808e278b22ec6b96f2faf7447d10cd8e</td>\n",
       "      <td>C∆° quan C·∫°nh tranh v√† Th·ªã tr∆∞·ªùng Anh quy·∫øt ƒë·ªãn...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>f81bdd6d8be4c5f64bb664214e47aced</td>\n",
       "      <td>Th√™m 7 ca t·∫°i Qu·∫£ng Nam li√™n quan ƒë·∫øn h√†nh kh√°...</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>ffc4b6bab27c40cfc48e4dc8b8a41e42</td>\n",
       "      <td>Trong gi·ªù h·ªçc Th·ªÉ d·ª•‚Äåc do th·∫ßy gi√°o Nguy·ªÖn VƒÉn...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                         user_name  \\\n",
       "0   1  389c669730cb6c54314a46be785cea42   \n",
       "1   3  b9f3394d2aff86d85974f5040c401f08   \n",
       "2   4  808e278b22ec6b96f2faf7447d10cd8e   \n",
       "3   5  f81bdd6d8be4c5f64bb664214e47aced   \n",
       "4   6  ffc4b6bab27c40cfc48e4dc8b8a41e42   \n",
       "\n",
       "                                        post_message num_like_post  \\\n",
       "0  THƒÇNG C·∫§P B·∫¨C H√ÄM ƒê·ªêI V·ªöI 2 C√ÅN B·ªò, CHI·∫æN S·ª∏ H...         19477   \n",
       "1  T∆Ø V·∫§N M√ôA THI: C√°ch n·ªôp h·ªì s∆° ƒë·ªÉ tr√∫ng tuy·ªÉn ...            48   \n",
       "2  C∆° quan C·∫°nh tranh v√† Th·ªã tr∆∞·ªùng Anh quy·∫øt ƒë·ªãn...             3   \n",
       "3  Th√™m 7 ca t·∫°i Qu·∫£ng Nam li√™n quan ƒë·∫øn h√†nh kh√°...           775   \n",
       "4  Trong gi·ªù h·ªçc Th·ªÉ d·ª•‚Äåc do th·∫ßy gi√°o Nguy·ªÖn VƒÉn...             2   \n",
       "\n",
       "  num_comment_post num_share_post  label  user_name_labelEncoder  \n",
       "0              378          173.0      0                    1032  \n",
       "1                5           19.0      0                    2804  \n",
       "2                0            0.0      0                    2044  \n",
       "3                0           54.0      0                    3575  \n",
       "4                1              0      0                    3701  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop id, user_name, timestamp_post columns\n",
    "data = data.drop(['timestamp_post', 'Unnamed: 0'], axis=1).reset_index(drop=True)\n",
    "\n",
    "# label encoding for user_name\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labels = data.user_name.values\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['user_name_labelEncoder'] = pd.Series(le.fit_transform(labels))\n",
    "\n",
    "# drop duplicate samples has <URL>, [<URL>](<URL>)\n",
    "char_drop = ['<URL>', '[<URL>](<URL>)']\n",
    "index = []\n",
    "for char in char_drop:\n",
    "    index.extend(list(data[data.post_message == char].index))\n",
    "data = data.drop(index, axis=0).reset_index(drop=True)\n",
    "\n",
    "# view data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc0bb6de-f5da-4187-8032-fa6698060852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>post_message</th>\n",
       "      <th>num_like_post</th>\n",
       "      <th>num_comment_post</th>\n",
       "      <th>num_share_post</th>\n",
       "      <th>label</th>\n",
       "      <th>user_name_labelEncoder</th>\n",
       "      <th>user_name_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>389c669730cb6c54314a46be785cea42</td>\n",
       "      <td>THƒÇNG C·∫§P B·∫¨C H√ÄM ƒê·ªêI V·ªöI 2 C√ÅN B·ªò, CHI·∫æN S·ª∏ H...</td>\n",
       "      <td>19477</td>\n",
       "      <td>378</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1032</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>b9f3394d2aff86d85974f5040c401f08</td>\n",
       "      <td>T∆Ø V·∫§N M√ôA THI: C√°ch n·ªôp h·ªì s∆° ƒë·ªÉ tr√∫ng tuy·ªÉn ...</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>808e278b22ec6b96f2faf7447d10cd8e</td>\n",
       "      <td>C∆° quan C·∫°nh tranh v√† Th·ªã tr∆∞·ªùng Anh quy·∫øt ƒë·ªãn...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2044</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>f81bdd6d8be4c5f64bb664214e47aced</td>\n",
       "      <td>Th√™m 7 ca t·∫°i Qu·∫£ng Nam li√™n quan ƒë·∫øn h√†nh kh√°...</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>ffc4b6bab27c40cfc48e4dc8b8a41e42</td>\n",
       "      <td>Trong gi·ªù h·ªçc Th·ªÉ d·ª•‚Äåc do th·∫ßy gi√°o Nguy·ªÖn VƒÉn...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                         user_name  \\\n",
       "0   1  389c669730cb6c54314a46be785cea42   \n",
       "1   3  b9f3394d2aff86d85974f5040c401f08   \n",
       "2   4  808e278b22ec6b96f2faf7447d10cd8e   \n",
       "3   5  f81bdd6d8be4c5f64bb664214e47aced   \n",
       "4   6  ffc4b6bab27c40cfc48e4dc8b8a41e42   \n",
       "\n",
       "                                        post_message num_like_post  \\\n",
       "0  THƒÇNG C·∫§P B·∫¨C H√ÄM ƒê·ªêI V·ªöI 2 C√ÅN B·ªò, CHI·∫æN S·ª∏ H...         19477   \n",
       "1  T∆Ø V·∫§N M√ôA THI: C√°ch n·ªôp h·ªì s∆° ƒë·ªÉ tr√∫ng tuy·ªÉn ...            48   \n",
       "2  C∆° quan C·∫°nh tranh v√† Th·ªã tr∆∞·ªùng Anh quy·∫øt ƒë·ªãn...             3   \n",
       "3  Th√™m 7 ca t·∫°i Qu·∫£ng Nam li√™n quan ƒë·∫øn h√†nh kh√°...           775   \n",
       "4  Trong gi·ªù h·ªçc Th·ªÉ d·ª•‚Äåc do th·∫ßy gi√°o Nguy·ªÖn VƒÉn...             2   \n",
       "\n",
       "  num_comment_post num_share_post  label  user_name_labelEncoder  \\\n",
       "0              378          173.0      0                    1032   \n",
       "1                5           19.0      0                    2804   \n",
       "2                0            0.0      0                    2044   \n",
       "3                0           54.0      0                    3575   \n",
       "4                1              0      0                    3701   \n",
       "\n",
       "   user_name_freq  \n",
       "0              58  \n",
       "1               1  \n",
       "2              64  \n",
       "3               1  \n",
       "4               1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_name_freq = data['user_name'].value_counts()\n",
    "\n",
    " \n",
    "data['user_name_freq'] = data['user_name'].map(user_name_freq)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94ad86f4-09c5-40c6-a473-5868f6c69c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in ['num_comment_post', 'num_like_post', 'num_share_post']:\n",
    "    data = data[pd.to_numeric(data[col], errors='coerce').notnull()]\n",
    "\n",
    "# ƒê·ªïi ki·ªÉu d·ªØ li·ªáu c√°c c·ªôt sang int64\n",
    "for col in ['num_comment_post', 'num_like_post', 'num_share_post']:\n",
    "    data[col] = pd.to_numeric(data[col]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7202413-1422-4200-a8c3-4cffe0d8a34c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4957 entries, 0 to 5110\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   id                      4957 non-null   int64 \n",
      " 1   user_name               4957 non-null   object\n",
      " 2   post_message            4957 non-null   object\n",
      " 3   num_like_post           4957 non-null   int64 \n",
      " 4   num_comment_post        4957 non-null   int64 \n",
      " 5   num_share_post          4957 non-null   int64 \n",
      " 6   label                   4957 non-null   int64 \n",
      " 7   user_name_labelEncoder  4957 non-null   int32 \n",
      " 8   user_name_freq          4957 non-null   int64 \n",
      "dtypes: int32(1), int64(6), object(2)\n",
      "memory usage: 367.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cd01113-7623-4e95-a01e-8d09f18cd94b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji==0.6.0\n",
      "  Using cached emoji-0.6.0.tar.gz (51 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-0.6.0-py3-none-any.whl size=49743 sha256=5bda887c280baf190a441de3fb8d6c263b5f69603fe599dc52fa290f7cb1acc7\n",
      "  Stored in directory: c:\\users\\lhuup\\appdata\\local\\pip\\cache\\wheels\\0d\\bf\\a2\\536017b4a6232aef0fb92831af35facd6590c0af0f3983f63b\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6d9f0b2-6480-4fce-afdc-5a4a511356ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "import emoji\n",
    "import unicodedata\n",
    "import regex as re\n",
    "import copy\n",
    "import string\n",
    "from vncorenlp import VnCoreNLP\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, split_alphanum, strip_short, strip_numeric\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# >>>Chu·∫©n h√≥a c√°ch ƒë·∫∑t d·∫•u ki·ªÉu c≈© -> m·ªõi. V√≠ d·ª• \"q·ªßa\"->\"qu·∫£\"\n",
    "# >>>V√≠ d·ª•: \n",
    "# >>>test_string = \"to·∫£n t·ªèan t·ªèa to·∫£ qu·∫£ q·ªßa qu·∫ø q√∫√™\"\n",
    "# >>>print(test_string)\n",
    "# >>>standardize_vi_sentence_accents(test_string)\n",
    "\n",
    "# => to·∫£n t·ªèan t·ªèa to·∫£ qu·∫£ q·ªßa qu·∫ø q√∫√™\n",
    "#     'to·∫£n to·∫£n t·ªèa t·ªèa qu·∫£ qu·∫£ qu·∫ø qu·∫ø'\n",
    "\n",
    "bang_nguyen_am = [['a', '√†', '√°', '·∫£', '√£', '·∫°', 'a'],\n",
    "                  ['ƒÉ', '·∫±', '·∫Ø', '·∫≥', '·∫µ', '·∫∑', 'aw'],\n",
    "                  ['√¢', '·∫ß', '·∫•', '·∫©', '·∫´', '·∫≠', 'aa'],\n",
    "                  ['e', '√®', '√©', '·∫ª', '·∫Ω', '·∫π', 'e'],\n",
    "                  ['√™', '·ªÅ', '·∫ø', '·ªÉ', '·ªÖ', '·ªá', 'ee'],\n",
    "                  ['i', '√¨', '√≠', '·ªâ', 'ƒ©', '·ªã', 'i'],\n",
    "                  ['o', '√≤', '√≥', '·ªè', '√µ', '·ªç', 'o'],\n",
    "                  ['√¥', '·ªì', '·ªë', '·ªï', '·ªó', '·ªô', 'oo'],\n",
    "                  ['∆°', '·ªù', '·ªõ', '·ªü', '·ª°', '·ª£', 'ow'],\n",
    "                  ['u', '√π', '√∫', '·ªß', '≈©', '·ª•', 'u'],\n",
    "                  ['∆∞', '·ª´', '·ª©', '·ª≠', '·ªØ', '·ª±', 'uw'],\n",
    "                  ['y', '·ª≥', '√Ω', '·ª∑', '·ªπ', '·ªµ', 'y']]\n",
    "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
    "\n",
    "nguyen_am_to_ids = {}\n",
    "\n",
    "for i in range(len(bang_nguyen_am)):\n",
    "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
    "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
    "\n",
    "\"\"\"\n",
    "    Start section: Chuy·ªÉn c√¢u vƒÉn v·ªÅ c√°ch g√µ d·∫•u ki·ªÉu c≈©: d√πng √≤a √∫y thay o√† u√Ω\n",
    "    Xem t·∫°i ƒë√¢y: https://vi.wikipedia.org/wiki/Quy_t·∫Øc_ƒë·∫∑t_d·∫•u_thanh_trong_ch·ªØ_qu·ªëc_ng·ªØ\n",
    "            C≈©\t                M·ªõi\n",
    "    √≤a, √≥a, ·ªèa, √µa, ·ªça\t|o√†, o√°, o·∫£, o√£, o·∫°\n",
    "    √≤e, √≥e, ·ªèe, √µe, ·ªçe\t|o√®, o√©, o·∫ª, o·∫Ω, o·∫π\n",
    "    √πy, √∫y, ·ªßy, ≈©y, ·ª•y\t|u·ª≥, u√Ω, u·ª∑, u·ªπ, u·ªµ\n",
    "\"\"\"\n",
    "\n",
    "def standardize_vi_word_accents(word):\n",
    "    if not is_valid_vietnam_word(word):\n",
    "        return word\n",
    "\n",
    "    chars = list(word)\n",
    "    dau_cau = 0\n",
    "    nguyen_am_index = []\n",
    "    qu_or_gi = False\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x == -1:\n",
    "            continue\n",
    "        elif x == 9:  # check qu\n",
    "            if index != 0 and chars[index - 1] == 'q':\n",
    "                chars[index] = 'u'\n",
    "                qu_or_gi = True\n",
    "        elif x == 5:  # check gi\n",
    "            if index != 0 and chars[index - 1] == 'g':\n",
    "                chars[index] = 'i'\n",
    "                qu_or_gi = True\n",
    "        if y != 0:\n",
    "            dau_cau = y\n",
    "            chars[index] = bang_nguyen_am[x][0]\n",
    "        if not qu_or_gi or index != 1:\n",
    "            nguyen_am_index.append(index)\n",
    "    if len(nguyen_am_index) < 2:\n",
    "        if qu_or_gi:\n",
    "            if len(chars) == 2:\n",
    "                x, y = nguyen_am_to_ids.get(chars[1])\n",
    "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
    "            else:\n",
    "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
    "                if x != -1:\n",
    "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
    "                else:\n",
    "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
    "            return ''.join(chars)\n",
    "        return word\n",
    "\n",
    "    for index in nguyen_am_index:\n",
    "        x, y = nguyen_am_to_ids[chars[index]]\n",
    "        if x == 4 or x == 8:  # √™, ∆°\n",
    "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
    "            return ''.join(chars)\n",
    "\n",
    "    if len(nguyen_am_index) == 2:\n",
    "        if nguyen_am_index[-1] == len(chars) - 1:\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
    "        else:\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "    else:\n",
    "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "    return ''.join(chars)\n",
    "\n",
    "def is_valid_vietnam_word(word):\n",
    "    chars = list(word)\n",
    "    nguyen_am_index = -1\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x != -1:\n",
    "            if nguyen_am_index == -1:\n",
    "                nguyen_am_index = index\n",
    "            else:\n",
    "                if index - nguyen_am_index != 1:\n",
    "                    return False\n",
    "                nguyen_am_index = index\n",
    "    return True\n",
    "\n",
    "\n",
    "def standardize_vi_sentence_accents(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    for index, word in enumerate(words):\n",
    "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
    "        if len(cw) == 3:\n",
    "            cw[1] = standardize_vi_word_accents(cw[1])\n",
    "        words[index] = ''.join(cw)\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Thay email, c√°c ƒë∆∞·ªùng d·∫´n link th√†nh MAIL, URL;  \n",
    "# Chuy·ªÉn emoij, emotion sang bi·ªÉu di·ªÖn t·ª´ c√≥ nghƒ©a;\n",
    "# Chu·∫©n h√≥a t·ª´ b·ªã l·∫∑p l·∫°i ki·ªÉu \"c∆°mmmm th√¥i\" hay \"th√¥ii:\n",
    "\n",
    "# VD:\n",
    "# >>>test_mail = \"khai@gmail.com vcsdl@gd.sr.hk bdf@ydf.df.com\"\n",
    "# >>>test_link = \"https:\\\\med.com.vn  www.hoag.com.vn uet.vnu.vn\"\n",
    "# >>>test_emoji_emotion = \"üòÇüòÇ :v :) ^_^ ^-^ @_@\"\n",
    "# >>>print(replace_email(test_mail))\n",
    "# >>>print(replace_link(test_link))\n",
    "# >>>print(convert_emojis(test_emoji_emotion))\n",
    "# >>>print(convert_emotions(test_emoji_emotion))\n",
    "\n",
    "# EMAIL EMAIL EMAILemojis.get_emoji_regexp()\n",
    "# https:\\URL\n",
    "# :face_with_tears_of_joy::face_with_tears_of_joy: :v :) ^_^ ^-^ @_@\n",
    "# üòÇüòÇ :v Happy_face_or_smiley Joyful ^-^ @_@\n",
    "\n",
    "def replace_email(text_str):\n",
    "  re_email = r'\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b'\n",
    "  match = re.findall(re_email ,text_str,re.IGNORECASE)\n",
    "  if not match:\n",
    "    return text_str\n",
    "  return re.sub(\"|\".join(match),\"EMAIL\",text_str)\n",
    "\n",
    "def replace_link(text_str):\n",
    "  re_link = r\"(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)\"\n",
    "  return re.sub(re_link, 'URL', text_str)\n",
    "\n",
    "def replace_emoji(text_str):\n",
    "\n",
    "  return emoji.get_emoji_regexp().sub(r' EMOJI ', text_str)\n",
    "  \n",
    "def convert_emojis(text):\n",
    "    for emot in UNICODE_EMO:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].split()))\n",
    "    return text\n",
    "\n",
    "def convert_emotions(text):\n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
    "    return text\n",
    "\n",
    "#******************************************************************************************************************\n",
    "# lo·∫°i b·ªè stop words b·∫±ng vietnamese-stopwords\n",
    "# Note: file ƒë·∫ßu v√†o d·∫°ng lowcase\n",
    "def get_stop_words(stopwords_file = \"vietnamese-stopwords/vietnamese-stopwords.txt\"):\n",
    "    with open(stopwords_file, \"r\", encoding='utf8') as file_sw:\n",
    "        stop_word = file_sw.read().split(sep='\\n')\n",
    "        # ƒë∆∞a v·ªÅ word d·∫°ng \"xin ch√†o\" th√†nh \"xin_ch√†o\" t∆∞∆°ng ·ª©ng v·ªõi b·ªô tokenize c·ªßa vncorenlp\n",
    "        stop_word = [word.replace(\" \", \"_\") for word in stop_word]\n",
    "    return stop_word\n",
    "\n",
    "def get_teencode_dict(teencode_file = \"dict_topic_word/teencode.txt\"):\n",
    "    teencode = pd.read_csv(teencode_file, sep=\"\\t\",\n",
    "                            header=None, names=[\"teencode\", \"standard_word\"])\n",
    "    teencode_dict = teencode.set_index(\"teencode\").to_dict()['standard_word']\n",
    "    return teencode_dict\n",
    "\n",
    "# Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu\n",
    "# text: ·ªü ƒë√¢y l√† m·ªôt document c√≥ th·ªÉ g·ªìm nhi·ªÅu c√¢u\n",
    "# ta s·∫Ω th·ª±c hi·ªán ti·ªÅn x·ª≠ l√Ω chu·∫©n h√≥a, clean,... ƒë·∫øn cu·ªëi c√πng s·∫Ω tokenize c·∫£\n",
    "# vƒÉn b·∫£n ban ƒë·∫ßu (ch·ª© kh√¥ng ph·∫£i l√†m theo t·ª´ng c√¢u), r·ªìi l·∫°i gh√©p l·∫°i l√†m 1 \"c√¢u\"\n",
    "# ƒë·∫°i di·ªán cho 1 vƒÉn b·∫£n c√≥ c√°c t·ª´ gh√©p n·ªëi v·ªõi nhau b·ªüi \"_\" 2 t·ª´ (t·ª´ gh√©p) ph√¢n \n",
    "# nhau b·ªüi d·∫•u space.\n",
    "# (Li·ªáu c√≥ ph·∫£i vncorenlp n√≥ hu·∫•n luy√™n tr√™n t·ª´ng c√¢u m√† gi·ªù m√¨nh tokenize c·∫£ vƒÉn\n",
    "# b·∫£n thay t·ª´ng c√¢u th√¨ c√≥ v·∫•n ƒë·ªÅ g√¨ kh√¥ng??)\n",
    "\n",
    "# ƒë·ªÉ sau n√†y embedding. ·ªû ƒë√¢y ta ƒëang ch∆°i embedding c·∫£ vƒÉn b·∫£n, b√†i vƒÉn ch·ª© kh√¥ng\n",
    "# embedding theo t·ª´ng c√¢u.\n",
    "\n",
    "# To perform word segmentation only\n",
    "annotator = VnCoreNLP(\"VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
    "\n",
    "def remove_dup_char(text):\n",
    "  return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def text_preprocessing(text, annotator=annotator, stopwords=[]):\n",
    "    # kwargs: annotator, stopwords\n",
    "  origin_text = copy.deepcopy(text)  \n",
    "  try:\n",
    "    text = unicodedata.normalize(\"NFC\", text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Chu·∫©n h√≥a c√°c t·ª´ c√≥ k√≠ t·ª± b·ªã l·∫∑p l·∫°i\n",
    "    text = remove_dup_char(text)\n",
    "\n",
    "    text = replace_email(text)\n",
    "    text = replace_emoji(text)\n",
    "\n",
    "    # Thay th·∫ø t·∫•t c·∫£ c√°c ƒë∆∞·ªùng d·∫´n trong vƒÉn b·∫£n.\n",
    "    text = replace_link(text)\n",
    "    \n",
    "    #remove punctuation\n",
    "    table = str.maketrans('', '',string.punctuation)\n",
    "    text = text.translate(table)\n",
    "\n",
    "    # T√°ch mix t·ª´ v√† s·ªë\n",
    "    text = split_alphanum(text)\n",
    "    # Lo·∫°i b·ªè to√†n b·ªô c√°c k√Ω t·ª± ƒë·ª©ng 1 m√¨nh\n",
    "    text = strip_short(text, minsize=2)\n",
    "    # Lo·∫°i b·ªè h·∫øt c√°c s·ªë trong vƒÉn b·∫£n\n",
    "    text = strip_numeric(text)\n",
    "\n",
    "    # Lo·∫°i b·ªè c√°c k√≠ t·ª± l·∫° nh∆∞ ‚â•\n",
    "    text = strip_non_alphanum(text)\n",
    "    # Chu·∫©n h√≥a c√°ch ƒë·∫∑t d·∫•u cho c√°c t·ª´ trong c√¢u: v√≠ d·ª• \"nh√¢n q·ªßa\" -> \"nh√¢n qu·∫£\" \n",
    "    text = standardize_vi_sentence_accents(text)\n",
    "    \n",
    "\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "      return \"EMPTY_STRING\"\n",
    "    #tokenize\n",
    "    # lu√¥n ch·ªâ c√≥ 1 ph·∫ßn t·ª´ n√™n l·∫•y [0]\n",
    "    # l√Ω do ch·ªâ c√≥ 1 ph·∫ßn t·ª≠ l√† v√¨ ta ƒë√£ x√≥a h·∫øt d·∫•u c√¢u c·∫£ vƒÉn b·∫£n coi l√† 1 c√¢u\n",
    "    # kh√¥ng c√≤n d·∫•u \".\" n√™n b·ªô tokenize xem nh∆∞ l√† 1 c√¢u n√™n ch·ªâ c√≥ 1 ph·∫ßn t·ª≠.\n",
    "    list_token = annotator.tokenize(text)[0]\n",
    "\n",
    "    # Chu·∫©n h√≥a teencode\n",
    "    # list_token = [teencode_dict.get(token, token) for token in list_token]\n",
    "\n",
    "    # remove stopword\n",
    "    list_token = [token for token in list_token if token not in stopwords]\n",
    "\n",
    "    norm_text = \" \".join(list_token)\n",
    "\n",
    "    return norm_text\n",
    "  except:\n",
    "    return \"EXCEPTION_STRING\"\n",
    "\n",
    "stopwords_file = \"vietnamese-stopwords/vietnamese-stopwords.txt\"\n",
    "\n",
    "stopwords = get_stop_words(stopwords_file)\n",
    "\n",
    "annotator = VnCoreNLP(\"VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
    "\n",
    "data['post_message_preproced'] = data.post_message.apply(text_preprocessing, stopwords= stopwords, annotator= annotator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "371292fa-eeca-4b07-bd2f-900ed2d65120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>post_message</th>\n",
       "      <th>num_like_post</th>\n",
       "      <th>num_comment_post</th>\n",
       "      <th>num_share_post</th>\n",
       "      <th>label</th>\n",
       "      <th>user_name_labelEncoder</th>\n",
       "      <th>user_name_freq</th>\n",
       "      <th>post_message_preproced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>389c669730cb6c54314a46be785cea42</td>\n",
       "      <td>THƒÇNG C·∫§P B·∫¨C H√ÄM ƒê·ªêI V·ªöI 2 C√ÅN B·ªò, CHI·∫æN S·ª∏ H...</td>\n",
       "      <td>19477</td>\n",
       "      <td>378</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>1032</td>\n",
       "      <td>58</td>\n",
       "      <td>EXCEPTION_STRING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>b9f3394d2aff86d85974f5040c401f08</td>\n",
       "      <td>T∆Ø V·∫§N M√ôA THI: C√°ch n·ªôp h·ªì s∆° ƒë·ªÉ tr√∫ng tuy·ªÉn ...</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2804</td>\n",
       "      <td>1</td>\n",
       "      <td>EXCEPTION_STRING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>808e278b22ec6b96f2faf7447d10cd8e</td>\n",
       "      <td>C∆° quan C·∫°nh tranh v√† Th·ªã tr∆∞·ªùng Anh quy·∫øt ƒë·ªãn...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2044</td>\n",
       "      <td>64</td>\n",
       "      <td>EXCEPTION_STRING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>f81bdd6d8be4c5f64bb664214e47aced</td>\n",
       "      <td>Th√™m 7 ca t·∫°i Qu·∫£ng Nam li√™n quan ƒë·∫øn h√†nh kh√°...</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>3575</td>\n",
       "      <td>1</td>\n",
       "      <td>EXCEPTION_STRING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>ffc4b6bab27c40cfc48e4dc8b8a41e42</td>\n",
       "      <td>Trong gi·ªù h·ªçc Th·ªÉ d·ª•‚Äåc do th·∫ßy gi√°o Nguy·ªÖn VƒÉn...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>1</td>\n",
       "      <td>EXCEPTION_STRING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                         user_name  \\\n",
       "0   1  389c669730cb6c54314a46be785cea42   \n",
       "1   3  b9f3394d2aff86d85974f5040c401f08   \n",
       "2   4  808e278b22ec6b96f2faf7447d10cd8e   \n",
       "3   5  f81bdd6d8be4c5f64bb664214e47aced   \n",
       "4   6  ffc4b6bab27c40cfc48e4dc8b8a41e42   \n",
       "\n",
       "                                        post_message  num_like_post  \\\n",
       "0  THƒÇNG C·∫§P B·∫¨C H√ÄM ƒê·ªêI V·ªöI 2 C√ÅN B·ªò, CHI·∫æN S·ª∏ H...          19477   \n",
       "1  T∆Ø V·∫§N M√ôA THI: C√°ch n·ªôp h·ªì s∆° ƒë·ªÉ tr√∫ng tuy·ªÉn ...             48   \n",
       "2  C∆° quan C·∫°nh tranh v√† Th·ªã tr∆∞·ªùng Anh quy·∫øt ƒë·ªãn...              3   \n",
       "3  Th√™m 7 ca t·∫°i Qu·∫£ng Nam li√™n quan ƒë·∫øn h√†nh kh√°...            775   \n",
       "4  Trong gi·ªù h·ªçc Th·ªÉ d·ª•‚Äåc do th·∫ßy gi√°o Nguy·ªÖn VƒÉn...              2   \n",
       "\n",
       "   num_comment_post  num_share_post  label  user_name_labelEncoder  \\\n",
       "0               378             173      0                    1032   \n",
       "1                 5              19      0                    2804   \n",
       "2                 0               0      0                    2044   \n",
       "3                 0              54      0                    3575   \n",
       "4                 1               0      0                    3701   \n",
       "\n",
       "   user_name_freq post_message_preproced  \n",
       "0              58       EXCEPTION_STRING  \n",
       "1               1       EXCEPTION_STRING  \n",
       "2              64       EXCEPTION_STRING  \n",
       "3               1       EXCEPTION_STRING  \n",
       "4               1       EXCEPTION_STRING  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c56238-066d-41ef-a62b-0384a24668f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
